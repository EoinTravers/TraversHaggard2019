{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook #1: Merge individual participants\n",
    "\n",
    "    NOTE: The raw EEG data are not provided in this repository.\n",
    "    This means you won't be able to run 0.Preprocess.ipynb or 1.Merge.ipynb.\n",
    "\n",
    "    These files are provided for completeness, and in the hope they might\n",
    "    be of use to other researchers.\n",
    "\n",
    "    Instead, we've included the preprocessed, epoched, and combined data as\n",
    "    - data/trial_epo.fif: Stimulus-locked epochs\n",
    "    - data/response_epo.fif: Response-locked epochs\n",
    "    \n",
    "    To start re-running the analyses, begin with 2.ERPs.ipynb.\n",
    "    \n",
    "The code in this notebook merges the epoch files for each participant,\n",
    "and produces some optional exploratory plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from mne import io\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "sys.path.append('src')\n",
    "import eegf # My generic EEG Functions\n",
    "import functions # Specific to this analysis\n",
    "\n",
    "mpl.rcParams['font.size'] = 20\n",
    "mpl.rcParams['axes.titlesize'] = 'medium'\n",
    "mpl.rcParams['axes.labelsize'] = 'medium'\n",
    "mpl.rcParams['xtick.labelsize'] = 'medium'\n",
    "mpl.rcParams['ytick.labelsize'] = 'medium'\n",
    "mpl.rcParams['legend.fontsize'] = 'medium'\n",
    "mpl.rcParams['figure.titlesize'] = 'medium'\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rc('font', family='DejaVu Sans')\n",
    "mpl.rcParams['svg.fonttype'] = 'none'\n",
    "million = 1000000.\n",
    "\n",
    "subjects = [1001, 1002, 1003, 1004,\n",
    "            1005, 1006,       1008,\n",
    "            1009, 1010, 1011, 1012,\n",
    "            1013, 1014, 1015, 1016,\n",
    "            1017, 1018, 1019, 1020,\n",
    "            1021]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_meta = False # Set to false to just read the merged data from file.\n",
    "if merge_meta:\n",
    "    subject_dfs = [functions.load_subject_csv(s) for s in subjects]\n",
    "    data = pd.concat(subject_dfs)\n",
    "    data.to_csv('data/all_trial_metadata.csv', index=False)\n",
    "else:\n",
    "    data = pd.read_csv('data/all_trial_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_data = data[data['rt'] > 0]\n",
    "response_data['rt'].hist(bins=50)\n",
    "plt.xlabel('RT')\n",
    "plt.title('%.2f%% of RTs < 3 s' % (np.mean(response_data['rt'] < 3)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subj_eeg(path, subject):\n",
    "    fp = os.path.join(path, '%i_epo.fif' % subject)\n",
    "    print('>>> Loading %s' % fp)\n",
    "    epochs = mne.read_epochs(fp, preload=True).resample(125)\n",
    "    return epochs\n",
    "\n",
    "def load_all_eeg(path, subjects):\n",
    "    subject_epochs = [load_subj_eeg(path, subject) for subject in subjects]\n",
    "    epochs = mne.epochs.concatenate_epochs(subject_epochs)\n",
    "    return epochs\n",
    "\n",
    "from functions import raw_by_subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stimulus (trial) locked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_trial = False\n",
    "if merge_trial:\n",
    "    trial_epochs = load_all_eeg('data/trial_epochs/', subjects)\n",
    "    trial_epochs = trial_epochs.filter(.2,  None)\n",
    "    trial_epochs.save('data/trial_epo.fif')\n",
    "    trial_epochs_csd = eegf.surface_laplacian(trial_epochs, m=5)\n",
    "    trial_epochs_csd.save('data/trial-csd_epo.fif')\n",
    "else:\n",
    "    trial_epochs = mne.read_epochs('data/trial_epo.fif')\n",
    "    trial_epochs_csd = mne.read_epochs('data/trial-csd_epo.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_erp(epochs, ch=9):\n",
    "    X = epochs.get_data()[:, ch]\n",
    "    eegf.plot_mean_sem(X, epochs.times)\n",
    "    plt.show()\n",
    "    \n",
    "plot_erp(trial_epochs, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_erp(trial_epochs_csd, 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a feel for the data\n",
    "\n",
    "You don't need to run any of this code, but it's useful to understand your data.\n",
    "You can skip ahead to the next section, which merges the response-locked data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlier_trials(epochs, thresh=120. / million):\n",
    "    X = epochs.get_data()[:, :32]\n",
    "    aX = np.abs(X).max(2).max(1)\n",
    "    return aX > thresh\n",
    "\n",
    "trial_rej = find_outlier_trials(trial_epochs, thresh=120./million)\n",
    "df = trial_epochs.metadata\n",
    "df['rej'] = trial_rej\n",
    "print(df.groupby('participant').mean()['rej'])\n",
    "print(trial_rej.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_epochs = trial_epochs[trial_rej==False]\n",
    "trial_epochs_csd = trial_epochs_csd[trial_rej==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_by_subject(trial_epochs, ch=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_by_subject(trial_epochs_csd, ch=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_by_subject(trial_epochs, show_raw=False, yl=30, ch=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Covariance between channels\n",
    "X = trial_epochs.get_data()[:, :32]\n",
    "_r = [np.corrcoef(X[i]) for i in range(len(X))]\n",
    "r = np.array(_r).mean(0)\n",
    "plt.figure()\n",
    "sns.heatmap(r, cmap='seismic', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlations: Standard data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trial_epochs_csd.get_data()[:, :32]\n",
    "_r = [np.corrcoef(X[i]) for i in range(len(X))]\n",
    "r = np.array(_r).mean(0)\n",
    "plt.figure()\n",
    "sns.heatmap(r, cmap='seismic', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Covariance: CSD data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_by_subject(trial_epochs_csd[rej==False], show_raw=False, yl=50, ch=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = functions.mean_by_subject(trial_epochs[trial_rej==False]) * million\n",
    "t = trial_epochs.times\n",
    "plt.figure(figsize=(20, 12))\n",
    "for i in range(20):\n",
    "    plt.plot(t, X[i, 26, :], label='S %i' % subjects[i])\n",
    "plt.legend()\n",
    "eegf.flipy()\n",
    "plt.title('Subject ERPs at CPz')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = functions.mean_by_subject(trial_epochs_csd[trial_rej==False]) * million\n",
    "t = trial_epochs.times\n",
    "plt.figure(figsize=(20, 12))\n",
    "for i in range(20):\n",
    "    plt.plot(t, X[i, 26, :], label='S %i' % subjects[i])\n",
    "plt.legend()\n",
    "eegf.flipy()\n",
    "plt.title('Subject CSD ERPs at CPz')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs, lbl in zip([trial_epochs, trial_epochs_csd], ['ERP', 'CSD ERP']):\n",
    "    X = functions.mean_by_subject(epochs)[:, 26] * million\n",
    "    eegf.plot_mean_sem(X, trial_epochs_csd.times, label=lbl)\n",
    "plt.legend()\n",
    "eegf.flipy()\n",
    "plt.title('Grand ERPs at CPz (Different units)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response-locked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_response = False\n",
    "if merge_response:\n",
    "    response_epochs = load_all_eeg('data/response_epochs/', subjects).filter(.2, None)\n",
    "    response_epochs.save('data/response_epo.fif')\n",
    "    response_epochs_csd = eegf.surface_laplacian(response_epochs, m=5)\n",
    "    response_epochs_csd.save('data/response-csd_epo.fif')\n",
    "else:\n",
    "    response_epochs = mne.read_epochs('data/response_epo.fif')\n",
    "    response_epochs_csd = mne.read_epochs('data/response-csd_epo.fif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_erp(response_epochs, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_erp(response_epochs_csd, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a feel for the data\n",
    "\n",
    "Again, you don't need to run anything from this point on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_rej = find_outlier_trials(response_epochs, thresh=120./million)\n",
    "df = response_epochs.metadata\n",
    "df['rej'] = resp_rej\n",
    "print(df.groupby('participant').mean()['rej'])\n",
    "print(resp_rej.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_epochs = response_epochs[resp_rej==False]\n",
    "response_epochs_csd = response_epochs_csd[resp_rej==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_by_subject(response_epochs, ch=9, yl=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_by_subject(response_epochs_csd, ch=9, yl=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_by_subject(response_epochs_csd, ch=9, yl=30, show_raw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Covariance between channels\n",
    "X = response_epochs.get_data()[:, :32]\n",
    "_r = [np.corrcoef(X[i]) for i in range(len(X))]\n",
    "r = np.array(_r).mean(0)\n",
    "plt.figure()\n",
    "sns.heatmap(r, cmap='seismic', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlations: Standard data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = response_epochs_csd.get_data()[:, :32]\n",
    "_r = [np.corrcoef(X[i]) for i in range(len(X))]\n",
    "r = np.array(_r).mean(0)\n",
    "plt.figure()\n",
    "sns.heatmap(r, cmap='seismic', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Covariance: CSD data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = functions.mean_by_subject(response_epochs) * million\n",
    "t = response_epochs.times\n",
    "plt.figure(figsize=(20, 12))\n",
    "for i in range(20):\n",
    "    plt.plot(t, X[i, 9, :], label='S %i' % subjects[i])\n",
    "plt.legend(loc='upper left')\n",
    "eegf.flipy()\n",
    "plt.title('Subject ERPs at FCz')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = functions.mean_by_subject(response_epochs_csd) * million\n",
    "t = response_epochs.times\n",
    "plt.figure(figsize=(20, 12))\n",
    "for i in range(20):\n",
    "    plt.plot(t, X[i, 9, :], label='S %i' % subjects[i])\n",
    "plt.legend(loc='upper left')\n",
    "eegf.flipy()\n",
    "plt.title('Subject CSD ERPs at FCz')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs, lbl in zip([response_epochs, response_epochs_csd], ['ERP', 'CSD ERP']):\n",
    "    X = functions.mean_by_subject(epochs)[:, 9] * million\n",
    "    eegf.plot_mean_sem(X, response_epochs_csd.times, label=lbl)\n",
    "plt.legend()\n",
    "eegf.flipy()\n",
    "plt.title('Grand ERPs at FCz (Different units)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
